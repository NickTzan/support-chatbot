{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 30636,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0e4468865a4c4e43a21146aad563b550": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4b3933a64e4047d0b7cc870e2adf46ba",
              "IPY_MODEL_f3a539fd900d4042b18343a0bf7873f7",
              "IPY_MODEL_73e85c51893c40bc91d229e04763e6be"
            ],
            "layout": "IPY_MODEL_aa6dd6ac017941509bd05fef32fc1eb5"
          }
        },
        "4b3933a64e4047d0b7cc870e2adf46ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9589b528a98d4fba9c4efade7f38092a",
            "placeholder": "​",
            "style": "IPY_MODEL_e9965fa77bcd4f39abcbcb7284ca30d9",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "f3a539fd900d4042b18343a0bf7873f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ac6d648f8464a859025466f55ad8896",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_19a8880a21ad46fa85985ebd3ca41665",
            "value": 2
          }
        },
        "73e85c51893c40bc91d229e04763e6be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ab15654e8fb4647a5578bf0a2fb17d9",
            "placeholder": "​",
            "style": "IPY_MODEL_1a38bad63e7b48398a4dd6d23df10565",
            "value": " 2/2 [01:16&lt;00:00, 35.47s/it]"
          }
        },
        "aa6dd6ac017941509bd05fef32fc1eb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9589b528a98d4fba9c4efade7f38092a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9965fa77bcd4f39abcbcb7284ca30d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ac6d648f8464a859025466f55ad8896": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19a8880a21ad46fa85985ebd3ca41665": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6ab15654e8fb4647a5578bf0a2fb17d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a38bad63e7b48398a4dd6d23df10565": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install the necessary dependencies\n",
        "!pip install xformer --quiet\n",
        "!pip install chromadb --quiet\n",
        "!pip install selenium --quiet\n",
        "!pip install langchain --quiet\n",
        "!pip install accelerate --quiet\n",
        "!pip install transformers --quiet\n",
        "!pip install bitsandbytes --quiet\n",
        "!pip install unstructured --quiet\n",
        "!pip install sentence-transformers --quiet"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-01-29T20:17:42.504285Z",
          "iopub.execute_input": "2024-01-29T20:17:42.504958Z",
          "iopub.status.idle": "2024-01-29T20:20:23.900754Z",
          "shell.execute_reply.started": "2024-01-29T20:17:42.504926Z",
          "shell.execute_reply": "2024-01-29T20:20:23.899514Z"
        },
        "trusted": true,
        "id": "JfPQ5E0qLI4v"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import torch\n",
        "from textwrap import fill\n",
        "from langchain.prompts.chat import (\n",
        "    ChatPromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    )\n",
        "from langchain import PromptTemplate\n",
        "from langchain import HuggingFacePipeline\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.schema import AIMessage, HumanMessage\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.document_loaders import UnstructuredMarkdownLoader, UnstructuredURLLoader\n",
        "from langchain_community.document_loaders import UnstructuredURLLoader, SeleniumURLLoader\n",
        "from langchain.chains import LLMChain, SimpleSequentialChain, RetrievalQA, ConversationalRetrievalChain\n",
        "from transformers import BitsAndBytesConfig, AutoModelForCausalLM, AutoTokenizer, GenerationConfig, pipeline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-29T20:20:23.902901Z",
          "iopub.execute_input": "2024-01-29T20:20:23.903291Z",
          "iopub.status.idle": "2024-01-29T20:20:43.381370Z",
          "shell.execute_reply.started": "2024-01-29T20:20:23.903258Z",
          "shell.execute_reply": "2024-01-29T20:20:43.380579Z"
        },
        "trusted": true,
        "id": "q5bhD4StLI4w"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the model to be used\n",
        "MODEL_NAME = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
        "\n",
        "# Set the quantization configuration\n",
        "quantization_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        ")\n",
        "\n",
        "# Initialize a tokenizer for the Mistral-7B model\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Set up the model parameters\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME, torch_dtype=torch.float16,\n",
        "    trust_remote_code=True,\n",
        "    device_map=\"auto\",\n",
        "    quantization_config=quantization_config\n",
        ")\n",
        "\n",
        "# Specification of various generation parameters like max number of tokens\n",
        "generation_config = GenerationConfig.from_pretrained(MODEL_NAME)\n",
        "generation_config.max_new_tokens = 1024\n",
        "generation_config.temperature = 0.0001\n",
        "generation_config.top_p = 0.95\n",
        "generation_config.do_sample = True\n",
        "generation_config.repetition_penalty = 1.15\n",
        "\n",
        "# Define the text generation pipeline\n",
        "pipeline = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    return_full_text=True,\n",
        "    generation_config=generation_config,\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-29T20:20:43.382467Z",
          "iopub.execute_input": "2024-01-29T20:20:43.383063Z",
          "iopub.status.idle": "2024-01-29T20:22:11.712092Z",
          "shell.execute_reply.started": "2024-01-29T20:20:43.383036Z",
          "shell.execute_reply": "2024-01-29T20:22:11.711039Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "0e4468865a4c4e43a21146aad563b550",
            "4b3933a64e4047d0b7cc870e2adf46ba",
            "f3a539fd900d4042b18343a0bf7873f7",
            "73e85c51893c40bc91d229e04763e6be",
            "aa6dd6ac017941509bd05fef32fc1eb5",
            "9589b528a98d4fba9c4efade7f38092a",
            "e9965fa77bcd4f39abcbcb7284ca30d9",
            "3ac6d648f8464a859025466f55ad8896",
            "19a8880a21ad46fa85985ebd3ca41665",
            "6ab15654e8fb4647a5578bf0a2fb17d9",
            "1a38bad63e7b48398a4dd6d23df10565"
          ]
        },
        "id": "jeESTSJ2LI4x",
        "outputId": "6b9965d3-7470-4ab5-f6aa-c6ebb176ccf8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0e4468865a4c4e43a21146aad563b550"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The HuggingFacePipeline class is used to interact with the models in HuggingFace\n",
        "llm = HuggingFacePipeline(\n",
        "    pipeline=pipeline,\n",
        "    )"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-29T20:22:11.714425Z",
          "iopub.execute_input": "2024-01-29T20:22:11.714737Z",
          "iopub.status.idle": "2024-01-29T20:22:11.720444Z",
          "shell.execute_reply.started": "2024-01-29T20:22:11.714713Z",
          "shell.execute_reply": "2024-01-29T20:22:11.719385Z"
        },
        "trusted": true,
        "id": "zcM2IU-0LI4y"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Trying a sample query that will be answered based on the general knowledge of the model from pretraining\n",
        "query = \"What are some of the most famous momuments in Greece?\"\n",
        "result = llm(\n",
        "    query\n",
        ")\n",
        "\n",
        "print(query)\n",
        "print(result)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-29T20:22:11.721495Z",
          "iopub.execute_input": "2024-01-29T20:22:11.721764Z",
          "iopub.status.idle": "2024-01-29T20:22:25.528205Z",
          "shell.execute_reply.started": "2024-01-29T20:22:11.721742Z",
          "shell.execute_reply": "2024-01-29T20:22:25.527167Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltZO_v5dLI4y",
        "outputId": "2606ef8c-8a65-43a9-b379-c52ede364e48"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What are some of the most famous momuments in Greece?\n",
            "\n",
            "\n",
            "## Answer (1)\n",
            "\n",
            "The Parthenon is probably the most famous monument in Greece. It's located on the Acropolis in Athens and was built between 447-432 BC as a temple to the goddess Athena.\n",
            "\n",
            "Another famous monument is the Colosseum, which is located in Rome but was built by the Romans who conquered Greece. The Colosseum was completed in 80 AD and could hold up to 50,000 spectators.\n",
            "\n",
            "Other notable monuments include the Statue of Zeus at Olympia, the Temple of Apollo at Delphi, and the Mausoleum at Halicarnassus.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up an embedding model\n",
        "# The model that will be used is the GTE model which is also hosted on HuggingFace\n",
        "embeddings = HuggingFaceEmbeddings(\n",
        "    model_name=\"thenlper/gte-large\",\n",
        "    model_kwargs={\"device\": \"cuda\"},\n",
        "    encode_kwargs={\"normalize_embeddings\": True},\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-29T20:22:25.529279Z",
          "iopub.execute_input": "2024-01-29T20:22:25.529554Z",
          "iopub.status.idle": "2024-01-29T20:23:20.040315Z",
          "shell.execute_reply.started": "2024-01-29T20:22:25.529530Z",
          "shell.execute_reply": "2024-01-29T20:23:20.039507Z"
        },
        "trusted": true,
        "id": "gbFitolRLI4z"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a prompt template to help guide the answers of the LLM\n",
        "template = \"\"\"\n",
        "Act as a history teacher who is teaching high school students.\n",
        "\n",
        "{text}\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"text\"],\n",
        "    template=template,\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-29T20:23:20.041562Z",
          "iopub.execute_input": "2024-01-29T20:23:20.041866Z",
          "iopub.status.idle": "2024-01-29T20:23:20.046614Z",
          "shell.execute_reply.started": "2024-01-29T20:23:20.041841Z",
          "shell.execute_reply": "2024-01-29T20:23:20.045754Z"
        },
        "trusted": true,
        "id": "U3QWx7PkLI4z"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A sample query using the newly created prompt template\n",
        "query = \"Explain the basic concepts of democracy in ancient Greece in around 4-5 sentences.\"\n",
        "result = llm(prompt.format(text=query))\n",
        "\n",
        "print(query)\n",
        "print(result)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-29T20:23:20.047754Z",
          "iopub.execute_input": "2024-01-29T20:23:20.048104Z",
          "iopub.status.idle": "2024-01-29T20:23:31.688599Z",
          "shell.execute_reply.started": "2024-01-29T20:23:20.048073Z",
          "shell.execute_reply": "2024-01-29T20:23:31.687563Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QNKkiLALI40",
        "outputId": "332193cf-ae37-4484-e597-1352a54dec5d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Explain the basic concepts of democracy in ancient Greece in around 4-5 sentences.\n",
            "\n",
            "Democracy in ancient Greece was based on the idea that every citizen had an equal say in government, regardless of their social status or wealth. This meant that all citizens were able to participate in decision making processes and vote on laws and policies. The concept of democracy was first introduced by Athenians in the 6th century BCE, and it quickly spread throughout other city-states in Greece. However, democracy was not without its flaws, and there were often conflicts between different groups with differing opinions. Despite these challenges, democracy remained a fundamental part of Greek society for centuries to come.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using some pages that were scraped from the internet as context. Selenium was used for the scraping\n",
        "urls = [\n",
        "    \"https://en.wikipedia.org/wiki/Bechdel_test\",\n",
        "    \"https://en.wikipedia.org/wiki/Alison_Bechdel\",\n",
        "]\n",
        "\n",
        "loader = SeleniumURLLoader(urls=urls)\n",
        "documents = loader.load()\n",
        "\n",
        "len(documents)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-29T20:23:31.689810Z",
          "iopub.execute_input": "2024-01-29T20:23:31.690116Z",
          "iopub.status.idle": "2024-01-29T20:23:48.792502Z",
          "shell.execute_reply.started": "2024-01-29T20:23:31.690091Z",
          "shell.execute_reply": "2024-01-29T20:23:48.791564Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZLTDeLsLI43",
        "outputId": "f9b8be96-0eb0-4f33-c3e0-cdba6e2657f4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the scraped documents into smaller chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=64)\n",
        "texts_chunks = text_splitter.split_documents(documents)\n",
        "\n",
        "len(texts_chunks)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-29T20:23:48.795259Z",
          "iopub.execute_input": "2024-01-29T20:23:48.795897Z",
          "iopub.status.idle": "2024-01-29T20:23:48.813070Z",
          "shell.execute_reply.started": "2024-01-29T20:23:48.795868Z",
          "shell.execute_reply": "2024-01-29T20:23:48.812014Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "maoseLSVLI43",
        "outputId": "2edf287b-a157-47b1-c3bf-40ef2a8aee66"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "77"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the ChromaDB vector store\n",
        "db = Chroma.from_documents(texts_chunks, embeddings, persist_directory=\"db\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-29T20:23:48.814378Z",
          "iopub.execute_input": "2024-01-29T20:23:48.815110Z",
          "iopub.status.idle": "2024-01-29T20:23:54.215415Z",
          "shell.execute_reply.started": "2024-01-29T20:23:48.815074Z",
          "shell.execute_reply": "2024-01-29T20:23:54.214362Z"
        },
        "trusted": true,
        "id": "Y-S6Sxt_LI43"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Customizing the template to use the context from the vector store\n",
        "template = \"\"\"\n",
        "Use the provided information to answer the question posed at the end. If the answer cannot be inferred from the context, then you should answer 'I don't know'.\n",
        "\n",
        "{context}\n",
        "\n",
        "{question}\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(template=template, input_variables=[\"context\", \"question\"])\n",
        "\n",
        "# Setting up the QA chain\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    # k=2 means that the 2 most relevant chunks will be used for the generated answer\n",
        "    retriever=db.as_retriever(search_kwargs={\"k\": 2}),\n",
        "    return_source_documents=True,\n",
        "    chain_type_kwargs={\"prompt\": prompt},\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-29T20:23:54.216690Z",
          "iopub.execute_input": "2024-01-29T20:23:54.217039Z",
          "iopub.status.idle": "2024-01-29T20:23:54.224677Z",
          "shell.execute_reply.started": "2024-01-29T20:23:54.217011Z",
          "shell.execute_reply": "2024-01-29T20:23:54.223382Z"
        },
        "trusted": true,
        "id": "0Va3WGohLI44"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Trying a new query with the provided context\n",
        "query = \"What is the Josephs test?\"\n",
        "result_ = qa_chain(\n",
        "    query\n",
        ")\n",
        "result = result_[\"result\"].strip()\n",
        "\n",
        "\n",
        "print(query)\n",
        "print(result)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-29T20:23:54.226208Z",
          "iopub.execute_input": "2024-01-29T20:23:54.226511Z",
          "iopub.status.idle": "2024-01-29T20:24:02.294504Z",
          "shell.execute_reply.started": "2024-01-29T20:23:54.226486Z",
          "shell.execute_reply": "2024-01-29T20:24:02.293518Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gniemuKGLI44",
        "outputId": "6785ed79-8aba-4981-d811-976e53ba85a7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is the Josephs test?\n",
            "The Josephs test is a set of criteria that can be used to evaluate whether a work of fiction accurately represents the lives of Orthodox Jews. It was proposed by the nonprofit organization Jewish In The City following a controversy over misrepresentation of Orthodox Judaism in television. The test consists of four questions:\n",
            "\n",
            "1. Are there any Orthodox characters who are emotionally and psychologically stable?\n",
            "2. Are there characters who are Orthodox whose religious life is a characteristic but not a plot point or a problem?\n",
            "3. Can the Orthodox character find their Happily Ever After as a religious Jew?\n",
            "4. And if the main plot points are in conflict due to religious observance — are any characters not Hasidic or Haredi and have the writers actually researched authentic religious observance from practicing members of the community they are attempting to portray?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementing memory for the conversation\n",
        "custom_template = \"\"\"You are an AI assistant. Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question. At the end of standalone question add this: 'Answer the question in English language.' If you do not know the answer reply with 'I am sorry, I dont have enough information'.\n",
        "Chat History: {chat_history}\n",
        "Follow Up Input: {question}\n",
        "Standalone question:\n",
        "\"\"\"\n",
        "\n",
        "CUSTOM_QUESTION_PROMPT = PromptTemplate.from_template(custom_template)\n",
        "\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "\n",
        "qa_chain = ConversationalRetrievalChain.from_llm(\n",
        "    llm=llm,\n",
        "    retriever=db.as_retriever(search_kwargs={\"k\": 2}),\n",
        "    memory=memory,\n",
        "    condense_question_prompt=CUSTOM_QUESTION_PROMPT,\n",
        ")"
      ],
      "metadata": {
        "id": "zKAMjON5QtNw"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Trying out a query\n",
        "query = \"What is the Josephs test?\"\n",
        "result_ = qa_chain({\"question\": query})\n",
        "result = result_[\"answer\"].strip()\n",
        "\n",
        "print(query)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_H-qcV3XRftI",
        "outputId": "5e0c73e8-021f-47b1-87ea-f6bbd87f264b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is the Josephs test?\n",
            "The Josephs Test is a set of criteria used to evaluate whether a fictional representation of Orthodox Jews accurately represents the community. It was proposed by the nonprofit organization Jewish In The City after a controversy over misrepresentation of Orthodox Judaism in television. The test includes four questions: Are there any Orthodox characters who are emotionally and psychologically stable? Are there characters who are Orthodox whose religious life is a characteristic but not a plot point or a problem? Can the Orthodox character find their Happily Ever After as a religious Jew? And if the main plot points are in conflict due to religious observance — are any characters not Hasidic or Haredi and have the writers actually researched authentic religious observance from practicing members of the community they are attempting to portray?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Making sure that memory works as intended\n",
        "query = \"What other similar tests do you know of?\"\n",
        "\n",
        "result_ = qa_chain({\"question\": query})\n",
        "result = result_[\"answer\"].strip()\n",
        "\n",
        "print(query)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8InkpaoTSycL",
        "outputId": "4f5132ce-cd27-4e4e-9d47-4a3dfa4e112d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What other similar tests do you know of?\n",
            "There are no other similar tests specifically designed to evaluate the accuracy of fictional representations of religious communities. However, there are general guidelines and best practices for creating accurate and respectful representations of all communities, including religious ones. These include conducting research, consulting with members of the community being represented, avoiding stereotypes and caricatures, and striving for nuanced and complex portrayals. Additionally, some organizations may offer workshops or training sessions on how to create more accurate and respectful representations of specific communities.\n"
          ]
        }
      ]
    }
  ]
}