{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import bs4\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader, WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_history_aware_retriever, create_retrieval_chain\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv('GROQ_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_llm():\n",
    "    llm = ChatGroq(groq_api_key=api_key, model_name=\"llama3-70b-8192\", temperature=0)\n",
    "    return llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_retriever():\n",
    "    loader = PyPDFLoader('pdf\\Attention-is-all-you-need.pdf')\n",
    "    # loader = WebBaseLoader(\n",
    "    #     web_paths=(\"https://www.nature.com/articles/s41467-020-16278-6\",),\n",
    "    #     bs_kwargs=dict(\n",
    "    #         parse_only=bs4.SoupStrainer(\n",
    "    #             class_=(\"c-article-title\", \"c-article-section__content\")\n",
    "    #         )\n",
    "    #     ),\n",
    "    # )\n",
    "    documents = loader.load()\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=64)\n",
    "    texts_chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\", model_kwargs={\"device\": \"cpu\"}, encode_kwargs={\"normalize_embeddings\": True},)\n",
    "    \n",
    "    db = Chroma.from_documents(documents=texts_chunks, embedding=embeddings)\n",
    "    retriever = db.as_retriever()\n",
    "    return retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_history_aware_retriever(llm, retriever):\n",
    "    contextualize_q_system_prompt = (\n",
    "        'Taking into account the chat history and the latest user question that may be referencing the chat history,'\n",
    "        'generate a new question that can be understood without the chat history. DO NOT answer that question,'\n",
    "        'just reformulate it if needed and otherwise return it as is.'\n",
    "    )\n",
    "    contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", contextualize_q_system_prompt),\n",
    "            MessagesPlaceholder(\"chat_history\"),\n",
    "            (\"human\", \"{input}\"),\n",
    "        ]\n",
    "    )\n",
    "    history_aware_retriever = create_history_aware_retriever(\n",
    "        llm, retriever, contextualize_q_prompt\n",
    "    )\n",
    "    return history_aware_retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_qa_chain(llm, history_aware_retriever):\n",
    "    system_prompt = (\n",
    "        'You are a helpful assistant that answers questions.'\n",
    "        'Use the retrieved context to answer the question.'\n",
    "        'If you do not know the answer your reply should be \"I dont know.\"'\n",
    "        'Try to keep the answers short unless otherwise specifed by the question.'\n",
    "        '\\n\\n'\n",
    "        '{context}'\n",
    "        )\n",
    "    qa_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system_prompt),\n",
    "            MessagesPlaceholder(\"chat_history\"),\n",
    "            (\"human\", \"{input}\"),\n",
    "        ]\n",
    "    )\n",
    "    question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
    "\n",
    "    qa_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)\n",
    "    return qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = {}\n",
    "\n",
    "llm = load_llm()\n",
    "retriever = prepare_retriever()\n",
    "history_aware_retriever = generate_history_aware_retriever(llm, retriever)\n",
    "rag_chain = create_qa_chain(llm, history_aware_retriever)\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "\n",
    "conversational_rag_chain = RunnableWithMessageHistory(\n",
    "    rag_chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    "    output_messages_key=\"answer\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_samples = {\n",
    "    'question': \n",
    "        [\n",
    "            'What is self-attention?', \n",
    "            'How many identical layers does the encoder of the transformer have?'\n",
    "        ],\n",
    "    'answer': \n",
    "        [],\n",
    "    'contexts' :\n",
    "        [\n",
    "            ['Self-attention, sometimes called intra-attention is an attention mechanism relating different positions of a single sequence in order to compute a representation of the sequence.'], \n",
    "            ['The encoder is composed of a stack of N = 6 identical layers.']\n",
    "        ],\n",
    "}\n",
    "# dataset = Dataset.from_dict(data_samples)\n",
    "# score = evaluate(dataset,metrics=[faithfulness], llm=ChatOllama(model='mistral'), embeddings=OllamaEmbeddings(model='mistral'))\n",
    "# score.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-630' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=TimeoutError()>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 853, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 323, in _agenerate\n",
      "    final_chunk = await self._achat_stream_with_aggregation(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 244, in _achat_stream_with_aggregation\n",
      "    async for stream_resp in self._acreate_chat_stream(messages, stop, **kwargs):\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 203, in _acreate_chat_stream\n",
      "    async for stream_resp in self._acreate_stream(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\langchain_community\\llms\\ollama.py\", line 297, in _acreate_stream\n",
      "    async with session.post(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\aiohttp\\client.py\", line 1197, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\aiohttp\\client.py\", line 608, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\aiohttp\\client_reqrep.py\", line 976, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\aiohttp\\streams.py\", line 640, in read\n",
      "    await self._waiter\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 285, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 234, in __step\n",
      "    result = coro.throw(exc)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_correctness.py\", line 250, in _ascore\n",
      "    is_statement_present = await self.llm.generate(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\llms\\base.py\", line 93, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\tenacity\\_asyncio.py\", line 88, in async_wrapped\n",
      "    return await fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\tenacity\\_asyncio.py\", line 47, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\tenacity\\__init__.py\", line 314, in iter\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\concurrent\\futures\\_base.py\", line 451, in result\n",
      "    return self.__get_result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\concurrent\\futures\\_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\tenacity\\_asyncio.py\", line 50, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\llms\\base.py\", line 178, in agenerate_text\n",
      "    result = await self.langchain_llm.agenerate_prompt(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 708, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in agenerate\n",
      "    results = await asyncio.gather(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 456, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 458, in wait_for\n",
      "    raise exceptions.TimeoutError() from exc\n",
      "asyncio.exceptions.TimeoutError\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-644' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=TimeoutError()>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 853, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 323, in _agenerate\n",
      "    final_chunk = await self._achat_stream_with_aggregation(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 244, in _achat_stream_with_aggregation\n",
      "    async for stream_resp in self._acreate_chat_stream(messages, stop, **kwargs):\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 203, in _acreate_chat_stream\n",
      "    async for stream_resp in self._acreate_stream(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\langchain_community\\llms\\ollama.py\", line 297, in _acreate_stream\n",
      "    async with session.post(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\aiohttp\\client.py\", line 1197, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\aiohttp\\client.py\", line 608, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\aiohttp\\client_reqrep.py\", line 976, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\aiohttp\\streams.py\", line 640, in read\n",
      "    await self._waiter\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 285, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 234, in __step\n",
      "    result = coro.throw(exc)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_correctness.py\", line 221, in _ascore\n",
      "    item_statement = await self.llm.generate(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\llms\\base.py\", line 93, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\tenacity\\_asyncio.py\", line 88, in async_wrapped\n",
      "    return await fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\tenacity\\_asyncio.py\", line 47, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\tenacity\\__init__.py\", line 314, in iter\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\concurrent\\futures\\_base.py\", line 451, in result\n",
      "    return self.__get_result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\concurrent\\futures\\_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\tenacity\\_asyncio.py\", line 50, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\llms\\base.py\", line 178, in agenerate_text\n",
      "    result = await self.langchain_llm.agenerate_prompt(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 708, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in agenerate\n",
      "    results = await asyncio.gather(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 456, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 458, in wait_for\n",
      "    raise exceptions.TimeoutError() from exc\n",
      "asyncio.exceptions.TimeoutError\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-651' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AttributeError(\"'NoneType' object has no attribute 'generate'\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_correctness.py\", line 250, in _ascore\n",
      "    is_statement_present = await self.llm.generate(\n",
      "AttributeError: 'NoneType' object has no attribute 'generate'\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-655' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('llm must be set to compute score')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 265, in _ascore\n",
      "    p_value = self._create_nli_prompt(row, statements)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 200, in _create_nli_prompt\n",
      "    assert self.llm is not None, \"llm must be set to compute score\"\n",
      "AssertionError: llm must be set to compute score\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-657' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError()>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 167, in _ascore\n",
      "    return self._calculate_score(answers, row)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 139, in _calculate_score\n",
      "    cosine_sim = self.calculate_similarity(question, gen_questions)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 112, in calculate_similarity\n",
      "    assert self.embeddings is not None\n",
      "AssertionError\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-658' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AttributeError(\"'NoneType' object has no attribute 'generate'\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_correctness.py\", line 221, in _ascore\n",
      "    item_statement = await self.llm.generate(\n",
      "AttributeError: 'NoneType' object has no attribute 'generate'\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-662' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('llm must be set to compute score')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 265, in _ascore\n",
      "    p_value = self._create_nli_prompt(row, statements)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 200, in _create_nli_prompt\n",
      "    assert self.llm is not None, \"llm must be set to compute score\"\n",
      "AssertionError: llm must be set to compute score\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-663' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AttributeError(\"'NoneType' object has no attribute 'embed_text'\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_similarity.py\", line 66, in _ascore\n",
      "    embedding_2 = np.array(await self.embeddings.embed_text(answer))\n",
      "AttributeError: 'NoneType' object has no attribute 'embed_text'\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-664' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError()>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 167, in _ascore\n",
      "    return self._calculate_score(answers, row)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 139, in _calculate_score\n",
      "    cosine_sim = self.calculate_similarity(question, gen_questions)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 112, in calculate_similarity\n",
      "    assert self.embeddings is not None\n",
      "AssertionError\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-665' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AttributeError(\"'NoneType' object has no attribute 'generate'\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_correctness.py\", line 221, in _ascore\n",
      "    item_statement = await self.llm.generate(\n",
      "AttributeError: 'NoneType' object has no attribute 'generate'\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-666' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('set LLM before use')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_context_recall.py\", line 167, in _ascore\n",
      "    assert self.llm is not None, \"set LLM before use\"\n",
      "AssertionError: set LLM before use\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-667' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('set LLM before use')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\critique.py\", line 123, in _ascore\n",
      "    assert self.llm is not None, \"set LLM before use\"\n",
      "AssertionError: set LLM before use\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-668' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_context_precision.py\", line 156, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-669' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 245, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-670' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('embeddings must be set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_similarity.py\", line 55, in _ascore\n",
      "    assert self.embeddings is not None, \"embeddings must be set\"\n",
      "AssertionError: embeddings must be set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-671' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 149, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-672' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM must be set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_correctness.py\", line 215, in _ascore\n",
      "    assert self.llm is not None, \"LLM must be set\"\n",
      "AssertionError: LLM must be set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-673' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('set LLM before use')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_context_recall.py\", line 167, in _ascore\n",
      "    assert self.llm is not None, \"set LLM before use\"\n",
      "AssertionError: set LLM before use\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-674' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('set LLM before use')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\critique.py\", line 123, in _ascore\n",
      "    assert self.llm is not None, \"set LLM before use\"\n",
      "AssertionError: set LLM before use\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-675' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_context_precision.py\", line 156, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-676' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 245, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-677' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('embeddings must be set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_similarity.py\", line 55, in _ascore\n",
      "    assert self.embeddings is not None, \"embeddings must be set\"\n",
      "AssertionError: embeddings must be set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-678' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 149, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-679' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM must be set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_correctness.py\", line 215, in _ascore\n",
      "    assert self.llm is not None, \"LLM must be set\"\n",
      "AssertionError: LLM must be set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-680' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('set LLM before use')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_context_recall.py\", line 167, in _ascore\n",
      "    assert self.llm is not None, \"set LLM before use\"\n",
      "AssertionError: set LLM before use\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-681' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('set LLM before use')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\critique.py\", line 123, in _ascore\n",
      "    assert self.llm is not None, \"set LLM before use\"\n",
      "AssertionError: set LLM before use\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-682' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_context_precision.py\", line 156, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-683' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 245, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-684' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('embeddings must be set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_similarity.py\", line 55, in _ascore\n",
      "    assert self.embeddings is not None, \"embeddings must be set\"\n",
      "AssertionError: embeddings must be set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-685' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 149, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-686' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM must be set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_correctness.py\", line 215, in _ascore\n",
      "    assert self.llm is not None, \"LLM must be set\"\n",
      "AssertionError: LLM must be set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-687' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('set LLM before use')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_context_recall.py\", line 167, in _ascore\n",
      "    assert self.llm is not None, \"set LLM before use\"\n",
      "AssertionError: set LLM before use\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-688' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('set LLM before use')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\critique.py\", line 123, in _ascore\n",
      "    assert self.llm is not None, \"set LLM before use\"\n",
      "AssertionError: set LLM before use\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-689' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_context_precision.py\", line 156, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-690' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 245, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-691' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('embeddings must be set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_similarity.py\", line 55, in _ascore\n",
      "    assert self.embeddings is not None, \"embeddings must be set\"\n",
      "AssertionError: embeddings must be set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-692' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 149, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-693' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM must be set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_correctness.py\", line 215, in _ascore\n",
      "    assert self.llm is not None, \"LLM must be set\"\n",
      "AssertionError: LLM must be set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-694' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('set LLM before use')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_context_recall.py\", line 167, in _ascore\n",
      "    assert self.llm is not None, \"set LLM before use\"\n",
      "AssertionError: set LLM before use\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-695' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('set LLM before use')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\critique.py\", line 123, in _ascore\n",
      "    assert self.llm is not None, \"set LLM before use\"\n",
      "AssertionError: set LLM before use\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-696' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_context_precision.py\", line 156, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-697' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 245, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-698' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('embeddings must be set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_similarity.py\", line 55, in _ascore\n",
      "    assert self.embeddings is not None, \"embeddings must be set\"\n",
      "AssertionError: embeddings must be set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-699' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 245, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-700' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 149, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-701' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM must be set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_correctness.py\", line 215, in _ascore\n",
      "    assert self.llm is not None, \"LLM must be set\"\n",
      "AssertionError: LLM must be set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-702' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('set LLM before use')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_context_recall.py\", line 167, in _ascore\n",
      "    assert self.llm is not None, \"set LLM before use\"\n",
      "AssertionError: set LLM before use\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-703' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('set LLM before use')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\critique.py\", line 123, in _ascore\n",
      "    assert self.llm is not None, \"set LLM before use\"\n",
      "AssertionError: set LLM before use\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-704' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_context_precision.py\", line 156, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-705' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 245, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-706' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('embeddings must be set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_similarity.py\", line 55, in _ascore\n",
      "    assert self.embeddings is not None, \"embeddings must be set\"\n",
      "AssertionError: embeddings must be set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-707' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 149, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-708' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM must be set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_correctness.py\", line 215, in _ascore\n",
      "    assert self.llm is not None, \"LLM must be set\"\n",
      "AssertionError: LLM must be set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-709' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('set LLM before use')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_context_recall.py\", line 167, in _ascore\n",
      "    assert self.llm is not None, \"set LLM before use\"\n",
      "AssertionError: set LLM before use\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-710' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('set LLM before use')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\critique.py\", line 123, in _ascore\n",
      "    assert self.llm is not None, \"set LLM before use\"\n",
      "AssertionError: set LLM before use\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-711' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_context_precision.py\", line 156, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-712' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 245, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-713' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('embeddings must be set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_similarity.py\", line 55, in _ascore\n",
      "    assert self.embeddings is not None, \"embeddings must be set\"\n",
      "AssertionError: embeddings must be set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-714' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 149, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-715' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM must be set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_correctness.py\", line 215, in _ascore\n",
      "    assert self.llm is not None, \"LLM must be set\"\n",
      "AssertionError: LLM must be set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-716' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('set LLM before use')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_context_recall.py\", line 167, in _ascore\n",
      "    assert self.llm is not None, \"set LLM before use\"\n",
      "AssertionError: set LLM before use\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-717' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('set LLM before use')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\critique.py\", line 123, in _ascore\n",
      "    assert self.llm is not None, \"set LLM before use\"\n",
      "AssertionError: set LLM before use\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-718' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_context_precision.py\", line 156, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-719' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 245, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-720' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('embeddings must be set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_similarity.py\", line 55, in _ascore\n",
      "    assert self.embeddings is not None, \"embeddings must be set\"\n",
      "AssertionError: embeddings must be set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-721' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 149, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-722' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM must be set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_correctness.py\", line 215, in _ascore\n",
      "    assert self.llm is not None, \"LLM must be set\"\n",
      "AssertionError: LLM must be set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-723' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('set LLM before use')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_context_recall.py\", line 167, in _ascore\n",
      "    assert self.llm is not None, \"set LLM before use\"\n",
      "AssertionError: set LLM before use\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-724' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('set LLM before use')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\critique.py\", line 123, in _ascore\n",
      "    assert self.llm is not None, \"set LLM before use\"\n",
      "AssertionError: set LLM before use\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-725' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_context_precision.py\", line 156, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-726' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 245, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-727' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('embeddings must be set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_similarity.py\", line 55, in _ascore\n",
      "    assert self.embeddings is not None, \"embeddings must be set\"\n",
      "AssertionError: embeddings must be set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-728' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 149, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-729' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM must be set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_correctness.py\", line 215, in _ascore\n",
      "    assert self.llm is not None, \"LLM must be set\"\n",
      "AssertionError: LLM must be set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-730' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('set LLM before use')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_context_recall.py\", line 167, in _ascore\n",
      "    assert self.llm is not None, \"set LLM before use\"\n",
      "AssertionError: set LLM before use\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-731' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('set LLM before use')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\critique.py\", line 123, in _ascore\n",
      "    assert self.llm is not None, \"set LLM before use\"\n",
      "AssertionError: set LLM before use\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-732' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_context_precision.py\", line 156, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-733' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 245, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-734' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('embeddings must be set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_similarity.py\", line 55, in _ascore\n",
      "    assert self.embeddings is not None, \"embeddings must be set\"\n",
      "AssertionError: embeddings must be set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-735' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 149, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-736' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM must be set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_correctness.py\", line 215, in _ascore\n",
      "    assert self.llm is not None, \"LLM must be set\"\n",
      "AssertionError: LLM must be set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-737' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('set LLM before use')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_context_recall.py\", line 167, in _ascore\n",
      "    assert self.llm is not None, \"set LLM before use\"\n",
      "AssertionError: set LLM before use\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-738' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('set LLM before use')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\critique.py\", line 123, in _ascore\n",
      "    assert self.llm is not None, \"set LLM before use\"\n",
      "AssertionError: set LLM before use\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-739' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_context_precision.py\", line 156, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-740' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 245, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-741' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('embeddings must be set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_similarity.py\", line 55, in _ascore\n",
      "    assert self.embeddings is not None, \"embeddings must be set\"\n",
      "AssertionError: embeddings must be set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-742' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 149, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-743' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM must be set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_correctness.py\", line 215, in _ascore\n",
      "    assert self.llm is not None, \"LLM must be set\"\n",
      "AssertionError: LLM must be set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-744' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 149, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-745' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('set LLM before use')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_context_recall.py\", line 167, in _ascore\n",
      "    assert self.llm is not None, \"set LLM before use\"\n",
      "AssertionError: set LLM before use\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-746' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('set LLM before use')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\critique.py\", line 123, in _ascore\n",
      "    assert self.llm is not None, \"set LLM before use\"\n",
      "AssertionError: set LLM before use\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-747' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_context_precision.py\", line 156, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-748' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 245, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-749' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('embeddings must be set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_similarity.py\", line 55, in _ascore\n",
      "    assert self.embeddings is not None, \"embeddings must be set\"\n",
      "AssertionError: embeddings must be set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-750' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 149, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-751' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM must be set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_correctness.py\", line 215, in _ascore\n",
      "    assert self.llm is not None, \"LLM must be set\"\n",
      "AssertionError: LLM must be set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-752' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('set LLM before use')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_context_recall.py\", line 167, in _ascore\n",
      "    assert self.llm is not None, \"set LLM before use\"\n",
      "AssertionError: set LLM before use\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-753' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('set LLM before use')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\critique.py\", line 123, in _ascore\n",
      "    assert self.llm is not None, \"set LLM before use\"\n",
      "AssertionError: set LLM before use\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-754' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_context_precision.py\", line 156, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-755' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('set LLM before use')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_context_recall.py\", line 167, in _ascore\n",
      "    assert self.llm is not None, \"set LLM before use\"\n",
      "AssertionError: set LLM before use\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-756' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('embeddings must be set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_similarity.py\", line 55, in _ascore\n",
      "    assert self.embeddings is not None, \"embeddings must be set\"\n",
      "AssertionError: embeddings must be set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-757' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 245, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-758' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_context_precision.py\", line 156, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-759' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM must be set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_correctness.py\", line 215, in _ascore\n",
      "    assert self.llm is not None, \"LLM must be set\"\n",
      "AssertionError: LLM must be set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-760' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 149, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-761' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('embeddings must be set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_similarity.py\", line 55, in _ascore\n",
      "    assert self.embeddings is not None, \"embeddings must be set\"\n",
      "AssertionError: embeddings must be set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-762' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('set LLM before use')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\critique.py\", line 123, in _ascore\n",
      "    assert self.llm is not None, \"set LLM before use\"\n",
      "AssertionError: set LLM before use\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-763' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('set LLM before use')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_context_recall.py\", line 167, in _ascore\n",
      "    assert self.llm is not None, \"set LLM before use\"\n",
      "AssertionError: set LLM before use\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-764' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM must be set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_correctness.py\", line 215, in _ascore\n",
      "    assert self.llm is not None, \"LLM must be set\"\n",
      "AssertionError: LLM must be set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-765' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 245, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-766' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_context_precision.py\", line 156, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-767' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('set LLM before use')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\critique.py\", line 123, in _ascore\n",
      "    assert self.llm is not None, \"set LLM before use\"\n",
      "AssertionError: set LLM before use\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-768' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 149, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-769' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('embeddings must be set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_similarity.py\", line 55, in _ascore\n",
      "    assert self.embeddings is not None, \"embeddings must be set\"\n",
      "AssertionError: embeddings must be set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-770' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 245, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-771' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('set LLM before use')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_context_recall.py\", line 167, in _ascore\n",
      "    assert self.llm is not None, \"set LLM before use\"\n",
      "AssertionError: set LLM before use\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-772' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM must be set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_correctness.py\", line 215, in _ascore\n",
      "    assert self.llm is not None, \"LLM must be set\"\n",
      "AssertionError: LLM must be set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-773' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 149, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-774' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_context_precision.py\", line 156, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-775' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('set LLM before use')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\critique.py\", line 123, in _ascore\n",
      "    assert self.llm is not None, \"set LLM before use\"\n",
      "AssertionError: set LLM before use\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-776' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('set LLM before use')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_context_recall.py\", line 167, in _ascore\n",
      "    assert self.llm is not None, \"set LLM before use\"\n",
      "AssertionError: set LLM before use\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-777' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('embeddings must be set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_similarity.py\", line 55, in _ascore\n",
      "    assert self.embeddings is not None, \"embeddings must be set\"\n",
      "AssertionError: embeddings must be set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-778' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_context_precision.py\", line 156, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-779' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM must be set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_correctness.py\", line 215, in _ascore\n",
      "    assert self.llm is not None, \"LLM must be set\"\n",
      "AssertionError: LLM must be set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-780' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('set LLM before use')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\critique.py\", line 123, in _ascore\n",
      "    assert self.llm is not None, \"set LLM before use\"\n",
      "AssertionError: set LLM before use\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4205' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=TimeoutError()>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 853, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 323, in _agenerate\n",
      "    final_chunk = await self._achat_stream_with_aggregation(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 244, in _achat_stream_with_aggregation\n",
      "    async for stream_resp in self._acreate_chat_stream(messages, stop, **kwargs):\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 203, in _acreate_chat_stream\n",
      "    async for stream_resp in self._acreate_stream(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\langchain_community\\llms\\ollama.py\", line 297, in _acreate_stream\n",
      "    async with session.post(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\aiohttp\\client.py\", line 1197, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\aiohttp\\client.py\", line 608, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\aiohttp\\client_reqrep.py\", line 976, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\aiohttp\\streams.py\", line 640, in read\n",
      "    await self._waiter\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 285, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 234, in __step\n",
      "    result = coro.throw(exc)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_correctness.py\", line 250, in _ascore\n",
      "    is_statement_present = await self.llm.generate(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\llms\\base.py\", line 93, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\tenacity\\_asyncio.py\", line 88, in async_wrapped\n",
      "    return await fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\tenacity\\_asyncio.py\", line 47, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\tenacity\\__init__.py\", line 314, in iter\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\concurrent\\futures\\_base.py\", line 451, in result\n",
      "    return self.__get_result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\concurrent\\futures\\_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\tenacity\\_asyncio.py\", line 50, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\llms\\base.py\", line 178, in agenerate_text\n",
      "    result = await self.langchain_llm.agenerate_prompt(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 708, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in agenerate\n",
      "    results = await asyncio.gather(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 456, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 458, in wait_for\n",
      "    raise exceptions.TimeoutError() from exc\n",
      "asyncio.exceptions.TimeoutError\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4206' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=TimeoutError()>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 853, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 323, in _agenerate\n",
      "    final_chunk = await self._achat_stream_with_aggregation(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 244, in _achat_stream_with_aggregation\n",
      "    async for stream_resp in self._acreate_chat_stream(messages, stop, **kwargs):\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 203, in _acreate_chat_stream\n",
      "    async for stream_resp in self._acreate_stream(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\langchain_community\\llms\\ollama.py\", line 297, in _acreate_stream\n",
      "    async with session.post(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\aiohttp\\client.py\", line 1197, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\aiohttp\\client.py\", line 608, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\aiohttp\\client_reqrep.py\", line 976, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\aiohttp\\streams.py\", line 640, in read\n",
      "    await self._waiter\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 285, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 234, in __step\n",
      "    result = coro.throw(exc)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_correctness.py\", line 250, in _ascore\n",
      "    is_statement_present = await self.llm.generate(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\llms\\base.py\", line 93, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\tenacity\\_asyncio.py\", line 88, in async_wrapped\n",
      "    return await fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\tenacity\\_asyncio.py\", line 47, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\tenacity\\__init__.py\", line 314, in iter\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\concurrent\\futures\\_base.py\", line 451, in result\n",
      "    return self.__get_result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\concurrent\\futures\\_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\tenacity\\_asyncio.py\", line 50, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\llms\\base.py\", line 178, in agenerate_text\n",
      "    result = await self.langchain_llm.agenerate_prompt(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 708, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in agenerate\n",
      "    results = await asyncio.gather(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 456, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 458, in wait_for\n",
      "    raise exceptions.TimeoutError() from exc\n",
      "asyncio.exceptions.TimeoutError\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4207' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=TimeoutError()>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 853, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 323, in _agenerate\n",
      "    final_chunk = await self._achat_stream_with_aggregation(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 244, in _achat_stream_with_aggregation\n",
      "    async for stream_resp in self._acreate_chat_stream(messages, stop, **kwargs):\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 203, in _acreate_chat_stream\n",
      "    async for stream_resp in self._acreate_stream(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\langchain_community\\llms\\ollama.py\", line 297, in _acreate_stream\n",
      "    async with session.post(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\aiohttp\\client.py\", line 1197, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\aiohttp\\client.py\", line 608, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\aiohttp\\client_reqrep.py\", line 976, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\aiohttp\\streams.py\", line 640, in read\n",
      "    await self._waiter\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 285, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 234, in __step\n",
      "    result = coro.throw(exc)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 266, in _ascore\n",
      "    nli_result = await self.llm.generate(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\llms\\base.py\", line 93, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\tenacity\\_asyncio.py\", line 88, in async_wrapped\n",
      "    return await fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\tenacity\\_asyncio.py\", line 47, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\tenacity\\__init__.py\", line 314, in iter\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\concurrent\\futures\\_base.py\", line 451, in result\n",
      "    return self.__get_result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\concurrent\\futures\\_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\tenacity\\_asyncio.py\", line 50, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\llms\\base.py\", line 178, in agenerate_text\n",
      "    result = await self.langchain_llm.agenerate_prompt(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 708, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in agenerate\n",
      "    results = await asyncio.gather(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 456, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 458, in wait_for\n",
      "    raise exceptions.TimeoutError() from exc\n",
      "asyncio.exceptions.TimeoutError\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4210' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=TimeoutError()>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 853, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 323, in _agenerate\n",
      "    final_chunk = await self._achat_stream_with_aggregation(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 244, in _achat_stream_with_aggregation\n",
      "    async for stream_resp in self._acreate_chat_stream(messages, stop, **kwargs):\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 203, in _acreate_chat_stream\n",
      "    async for stream_resp in self._acreate_stream(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\langchain_community\\llms\\ollama.py\", line 297, in _acreate_stream\n",
      "    async with session.post(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\aiohttp\\client.py\", line 1197, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\aiohttp\\client.py\", line 608, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\aiohttp\\client_reqrep.py\", line 976, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\aiohttp\\streams.py\", line 640, in read\n",
      "    await self._waiter\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 285, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 234, in __step\n",
      "    result = coro.throw(exc)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_correctness.py\", line 221, in _ascore\n",
      "    item_statement = await self.llm.generate(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\llms\\base.py\", line 93, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\tenacity\\_asyncio.py\", line 88, in async_wrapped\n",
      "    return await fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\tenacity\\_asyncio.py\", line 47, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\tenacity\\__init__.py\", line 314, in iter\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\concurrent\\futures\\_base.py\", line 451, in result\n",
      "    return self.__get_result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\concurrent\\futures\\_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\tenacity\\_asyncio.py\", line 50, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\llms\\base.py\", line 178, in agenerate_text\n",
      "    result = await self.langchain_llm.agenerate_prompt(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 708, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in agenerate\n",
      "    results = await asyncio.gather(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 456, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 458, in wait_for\n",
      "    raise exceptions.TimeoutError() from exc\n",
      "asyncio.exceptions.TimeoutError\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4215' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=TimeoutError()>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 853, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 323, in _agenerate\n",
      "    final_chunk = await self._achat_stream_with_aggregation(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 244, in _achat_stream_with_aggregation\n",
      "    async for stream_resp in self._acreate_chat_stream(messages, stop, **kwargs):\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 203, in _acreate_chat_stream\n",
      "    async for stream_resp in self._acreate_stream(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\langchain_community\\llms\\ollama.py\", line 297, in _acreate_stream\n",
      "    async with session.post(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\aiohttp\\client.py\", line 1197, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\aiohttp\\client.py\", line 608, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\aiohttp\\client_reqrep.py\", line 976, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\aiohttp\\streams.py\", line 640, in read\n",
      "    await self._waiter\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 285, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 234, in __step\n",
      "    result = coro.throw(exc)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_correctness.py\", line 250, in _ascore\n",
      "    is_statement_present = await self.llm.generate(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\llms\\base.py\", line 93, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\tenacity\\_asyncio.py\", line 88, in async_wrapped\n",
      "    return await fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\tenacity\\_asyncio.py\", line 47, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\tenacity\\__init__.py\", line 314, in iter\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\concurrent\\futures\\_base.py\", line 451, in result\n",
      "    return self.__get_result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\concurrent\\futures\\_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\tenacity\\_asyncio.py\", line 50, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\llms\\base.py\", line 178, in agenerate_text\n",
      "    result = await self.langchain_llm.agenerate_prompt(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 708, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in agenerate\n",
      "    results = await asyncio.gather(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 456, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 458, in wait_for\n",
      "    raise exceptions.TimeoutError() from exc\n",
      "asyncio.exceptions.TimeoutError\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4218' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError()>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 167, in _ascore\n",
      "    return self._calculate_score(answers, row)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 139, in _calculate_score\n",
      "    cosine_sim = self.calculate_similarity(question, gen_questions)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 112, in calculate_similarity\n",
      "    assert self.embeddings is not None\n",
      "AssertionError\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4219' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AttributeError(\"'NoneType' object has no attribute 'generate'\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_correctness.py\", line 221, in _ascore\n",
      "    item_statement = await self.llm.generate(\n",
      "AttributeError: 'NoneType' object has no attribute 'generate'\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4222' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('llm must be set to compute score')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 265, in _ascore\n",
      "    p_value = self._create_nli_prompt(row, statements)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 200, in _create_nli_prompt\n",
      "    assert self.llm is not None, \"llm must be set to compute score\"\n",
      "AssertionError: llm must be set to compute score\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4224' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AttributeError(\"'NoneType' object has no attribute 'generate'\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_correctness.py\", line 221, in _ascore\n",
      "    item_statement = await self.llm.generate(\n",
      "AttributeError: 'NoneType' object has no attribute 'generate'\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4225' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AttributeError(\"'NoneType' object has no attribute 'generate'\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_correctness.py\", line 221, in _ascore\n",
      "    item_statement = await self.llm.generate(\n",
      "AttributeError: 'NoneType' object has no attribute 'generate'\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4227' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('llm must be set to compute score')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 265, in _ascore\n",
      "    p_value = self._create_nli_prompt(row, statements)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 200, in _create_nli_prompt\n",
      "    assert self.llm is not None, \"llm must be set to compute score\"\n",
      "AssertionError: llm must be set to compute score\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4228' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AttributeError(\"'NoneType' object has no attribute 'embed_text'\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_similarity.py\", line 66, in _ascore\n",
      "    embedding_2 = np.array(await self.embeddings.embed_text(answer))\n",
      "AttributeError: 'NoneType' object has no attribute 'embed_text'\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4232' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AttributeError(\"'NoneType' object has no attribute 'generate'\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_correctness.py\", line 221, in _ascore\n",
      "    item_statement = await self.llm.generate(\n",
      "AttributeError: 'NoneType' object has no attribute 'generate'\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4235' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('embeddings must be set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_similarity.py\", line 55, in _ascore\n",
      "    assert self.embeddings is not None, \"embeddings must be set\"\n",
      "AssertionError: embeddings must be set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4236' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 149, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4237' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('set LLM before use')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\critique.py\", line 123, in _ascore\n",
      "    assert self.llm is not None, \"set LLM before use\"\n",
      "AssertionError: set LLM before use\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4238' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 245, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4239' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM must be set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_correctness.py\", line 215, in _ascore\n",
      "    assert self.llm is not None, \"LLM must be set\"\n",
      "AssertionError: LLM must be set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4240' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 149, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4241' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 149, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4242' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_context_precision.py\", line 156, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4243' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('embeddings must be set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_similarity.py\", line 55, in _ascore\n",
      "    assert self.embeddings is not None, \"embeddings must be set\"\n",
      "AssertionError: embeddings must be set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4244' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM must be set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_correctness.py\", line 215, in _ascore\n",
      "    assert self.llm is not None, \"LLM must be set\"\n",
      "AssertionError: LLM must be set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4245' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('set LLM before use')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\critique.py\", line 123, in _ascore\n",
      "    assert self.llm is not None, \"set LLM before use\"\n",
      "AssertionError: set LLM before use\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4246' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 245, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4247' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 245, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4248' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 149, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4249' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('set LLM before use')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\critique.py\", line 123, in _ascore\n",
      "    assert self.llm is not None, \"set LLM before use\"\n",
      "AssertionError: set LLM before use\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4250' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('set LLM before use')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_context_recall.py\", line 167, in _ascore\n",
      "    assert self.llm is not None, \"set LLM before use\"\n",
      "AssertionError: set LLM before use\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4251' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('set LLM before use')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_context_recall.py\", line 167, in _ascore\n",
      "    assert self.llm is not None, \"set LLM before use\"\n",
      "AssertionError: set LLM before use\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4252' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('embeddings must be set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_similarity.py\", line 55, in _ascore\n",
      "    assert self.embeddings is not None, \"embeddings must be set\"\n",
      "AssertionError: embeddings must be set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4253' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 245, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4254' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM must be set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_correctness.py\", line 215, in _ascore\n",
      "    assert self.llm is not None, \"LLM must be set\"\n",
      "AssertionError: LLM must be set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4255' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM must be set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_correctness.py\", line 215, in _ascore\n",
      "    assert self.llm is not None, \"LLM must be set\"\n",
      "AssertionError: LLM must be set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4256' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 149, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4257' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('set LLM before use')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\critique.py\", line 123, in _ascore\n",
      "    assert self.llm is not None, \"set LLM before use\"\n",
      "AssertionError: set LLM before use\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4258' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 149, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4259' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 245, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4260' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('embeddings must be set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_similarity.py\", line 55, in _ascore\n",
      "    assert self.embeddings is not None, \"embeddings must be set\"\n",
      "AssertionError: embeddings must be set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4261' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('set LLM before use')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_context_recall.py\", line 167, in _ascore\n",
      "    assert self.llm is not None, \"set LLM before use\"\n",
      "AssertionError: set LLM before use\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4262' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('set LLM before use')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\critique.py\", line 123, in _ascore\n",
      "    assert self.llm is not None, \"set LLM before use\"\n",
      "AssertionError: set LLM before use\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4263' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_context_precision.py\", line 156, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4264' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 245, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4265' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('embeddings must be set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_similarity.py\", line 55, in _ascore\n",
      "    assert self.embeddings is not None, \"embeddings must be set\"\n",
      "AssertionError: embeddings must be set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4266' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM must be set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_correctness.py\", line 215, in _ascore\n",
      "    assert self.llm is not None, \"LLM must be set\"\n",
      "AssertionError: LLM must be set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4267' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('set LLM before use')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\critique.py\", line 123, in _ascore\n",
      "    assert self.llm is not None, \"set LLM before use\"\n",
      "AssertionError: set LLM before use\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4268' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('embeddings must be set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_similarity.py\", line 55, in _ascore\n",
      "    assert self.embeddings is not None, \"embeddings must be set\"\n",
      "AssertionError: embeddings must be set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4269' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 245, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4270' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('set LLM before use')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\critique.py\", line 123, in _ascore\n",
      "    assert self.llm is not None, \"set LLM before use\"\n",
      "AssertionError: set LLM before use\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4271' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 245, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4272' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('set LLM before use')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_context_recall.py\", line 167, in _ascore\n",
      "    assert self.llm is not None, \"set LLM before use\"\n",
      "AssertionError: set LLM before use\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4273' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_context_precision.py\", line 156, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4274' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_context_precision.py\", line 156, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4275' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('embeddings must be set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_similarity.py\", line 55, in _ascore\n",
      "    assert self.embeddings is not None, \"embeddings must be set\"\n",
      "AssertionError: embeddings must be set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4276' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 149, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4277' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('embeddings must be set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_similarity.py\", line 55, in _ascore\n",
      "    assert self.embeddings is not None, \"embeddings must be set\"\n",
      "AssertionError: embeddings must be set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4278' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('set LLM before use')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\critique.py\", line 123, in _ascore\n",
      "    assert self.llm is not None, \"set LLM before use\"\n",
      "AssertionError: set LLM before use\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4279' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('embeddings must be set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_similarity.py\", line 55, in _ascore\n",
      "    assert self.embeddings is not None, \"embeddings must be set\"\n",
      "AssertionError: embeddings must be set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4280' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_context_precision.py\", line 156, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4281' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 245, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4282' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 149, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4283' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('embeddings must be set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_similarity.py\", line 55, in _ascore\n",
      "    assert self.embeddings is not None, \"embeddings must be set\"\n",
      "AssertionError: embeddings must be set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4284' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 245, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4285' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_context_precision.py\", line 156, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4286' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('set LLM before use')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\critique.py\", line 123, in _ascore\n",
      "    assert self.llm is not None, \"set LLM before use\"\n",
      "AssertionError: set LLM before use\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4287' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('embeddings must be set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_similarity.py\", line 55, in _ascore\n",
      "    assert self.embeddings is not None, \"embeddings must be set\"\n",
      "AssertionError: embeddings must be set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4288' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_context_precision.py\", line 156, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4289' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM must be set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_correctness.py\", line 215, in _ascore\n",
      "    assert self.llm is not None, \"LLM must be set\"\n",
      "AssertionError: LLM must be set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4290' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('set LLM before use')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_context_recall.py\", line 167, in _ascore\n",
      "    assert self.llm is not None, \"set LLM before use\"\n",
      "AssertionError: set LLM before use\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4291' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 149, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4292' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 245, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4293' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_context_precision.py\", line 156, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4294' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 149, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4295' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_context_precision.py\", line 156, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4296' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM must be set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_correctness.py\", line 215, in _ascore\n",
      "    assert self.llm is not None, \"LLM must be set\"\n",
      "AssertionError: LLM must be set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4297' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('set LLM before use')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_context_recall.py\", line 167, in _ascore\n",
      "    assert self.llm is not None, \"set LLM before use\"\n",
      "AssertionError: set LLM before use\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4298' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('set LLM before use')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_context_recall.py\", line 167, in _ascore\n",
      "    assert self.llm is not None, \"set LLM before use\"\n",
      "AssertionError: set LLM before use\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4299' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('set LLM before use')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\critique.py\", line 123, in _ascore\n",
      "    assert self.llm is not None, \"set LLM before use\"\n",
      "AssertionError: set LLM before use\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4300' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('embeddings must be set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_similarity.py\", line 55, in _ascore\n",
      "    assert self.embeddings is not None, \"embeddings must be set\"\n",
      "AssertionError: embeddings must be set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4301' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('embeddings must be set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_similarity.py\", line 55, in _ascore\n",
      "    assert self.embeddings is not None, \"embeddings must be set\"\n",
      "AssertionError: embeddings must be set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4302' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 149, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4303' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM must be set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_correctness.py\", line 215, in _ascore\n",
      "    assert self.llm is not None, \"LLM must be set\"\n",
      "AssertionError: LLM must be set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4304' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM must be set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_correctness.py\", line 215, in _ascore\n",
      "    assert self.llm is not None, \"LLM must be set\"\n",
      "AssertionError: LLM must be set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4305' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_context_precision.py\", line 156, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4306' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 149, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4307' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('set LLM before use')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\critique.py\", line 123, in _ascore\n",
      "    assert self.llm is not None, \"set LLM before use\"\n",
      "AssertionError: set LLM before use\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4308' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM must be set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_correctness.py\", line 215, in _ascore\n",
      "    assert self.llm is not None, \"LLM must be set\"\n",
      "AssertionError: LLM must be set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4309' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('set LLM before use')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\critique.py\", line 123, in _ascore\n",
      "    assert self.llm is not None, \"set LLM before use\"\n",
      "AssertionError: set LLM before use\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4310' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 149, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4311' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 245, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4312' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('set LLM before use')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_context_recall.py\", line 167, in _ascore\n",
      "    assert self.llm is not None, \"set LLM before use\"\n",
      "AssertionError: set LLM before use\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4313' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 149, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4314' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('set LLM before use')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\critique.py\", line 123, in _ascore\n",
      "    assert self.llm is not None, \"set LLM before use\"\n",
      "AssertionError: set LLM before use\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4315' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_context_precision.py\", line 156, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4316' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('set LLM before use')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_context_recall.py\", line 167, in _ascore\n",
      "    assert self.llm is not None, \"set LLM before use\"\n",
      "AssertionError: set LLM before use\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4317' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_context_precision.py\", line 156, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4318' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM must be set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_correctness.py\", line 215, in _ascore\n",
      "    assert self.llm is not None, \"LLM must be set\"\n",
      "AssertionError: LLM must be set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4319' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 245, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4320' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 149, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4321' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('set LLM before use')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\critique.py\", line 123, in _ascore\n",
      "    assert self.llm is not None, \"set LLM before use\"\n",
      "AssertionError: set LLM before use\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4322' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('embeddings must be set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_similarity.py\", line 55, in _ascore\n",
      "    assert self.embeddings is not None, \"embeddings must be set\"\n",
      "AssertionError: embeddings must be set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4323' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('set LLM before use')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\critique.py\", line 123, in _ascore\n",
      "    assert self.llm is not None, \"set LLM before use\"\n",
      "AssertionError: set LLM before use\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4324' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 245, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4325' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('set LLM before use')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_context_recall.py\", line 167, in _ascore\n",
      "    assert self.llm is not None, \"set LLM before use\"\n",
      "AssertionError: set LLM before use\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4326' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('set LLM before use')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_context_recall.py\", line 167, in _ascore\n",
      "    assert self.llm is not None, \"set LLM before use\"\n",
      "AssertionError: set LLM before use\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4327' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('set LLM before use')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_context_recall.py\", line 167, in _ascore\n",
      "    assert self.llm is not None, \"set LLM before use\"\n",
      "AssertionError: set LLM before use\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4328' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_context_precision.py\", line 156, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4329' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('embeddings must be set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_similarity.py\", line 55, in _ascore\n",
      "    assert self.embeddings is not None, \"embeddings must be set\"\n",
      "AssertionError: embeddings must be set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4330' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_context_precision.py\", line 156, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4331' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_context_precision.py\", line 156, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4332' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('embeddings must be set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_similarity.py\", line 55, in _ascore\n",
      "    assert self.embeddings is not None, \"embeddings must be set\"\n",
      "AssertionError: embeddings must be set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4333' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('set LLM before use')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\critique.py\", line 123, in _ascore\n",
      "    assert self.llm is not None, \"set LLM before use\"\n",
      "AssertionError: set LLM before use\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4334' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('set LLM before use')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\critique.py\", line 123, in _ascore\n",
      "    assert self.llm is not None, \"set LLM before use\"\n",
      "AssertionError: set LLM before use\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4335' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('set LLM before use')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_context_recall.py\", line 167, in _ascore\n",
      "    assert self.llm is not None, \"set LLM before use\"\n",
      "AssertionError: set LLM before use\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4336' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 245, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4337' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 245, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4338' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 149, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4339' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 149, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4340' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_context_precision.py\", line 156, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4341' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('set LLM before use')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_context_recall.py\", line 167, in _ascore\n",
      "    assert self.llm is not None, \"set LLM before use\"\n",
      "AssertionError: set LLM before use\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4342' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('embeddings must be set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_similarity.py\", line 55, in _ascore\n",
      "    assert self.embeddings is not None, \"embeddings must be set\"\n",
      "AssertionError: embeddings must be set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4343' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('set LLM before use')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_context_recall.py\", line 167, in _ascore\n",
      "    assert self.llm is not None, \"set LLM before use\"\n",
      "AssertionError: set LLM before use\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4344' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM must be set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_correctness.py\", line 215, in _ascore\n",
      "    assert self.llm is not None, \"LLM must be set\"\n",
      "AssertionError: LLM must be set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4345' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('set LLM before use')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_context_recall.py\", line 167, in _ascore\n",
      "    assert self.llm is not None, \"set LLM before use\"\n",
      "AssertionError: set LLM before use\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4346' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 245, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4347' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 149, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4348' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 245, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4349' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('set LLM before use')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_context_recall.py\", line 167, in _ascore\n",
      "    assert self.llm is not None, \"set LLM before use\"\n",
      "AssertionError: set LLM before use\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4350' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM must be set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_correctness.py\", line 215, in _ascore\n",
      "    assert self.llm is not None, \"LLM must be set\"\n",
      "AssertionError: LLM must be set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4351' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 149, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4352' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('LLM is not set')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 245, in _ascore\n",
      "    assert self.llm is not None, \"LLM is not set\"\n",
      "AssertionError: LLM is not set\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-4353' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('set LLM before use')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_context_recall.py\", line 167, in _ascore\n",
      "    assert self.llm is not None, \"set LLM before use\"\n",
      "AssertionError: set LLM before use\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-6789' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=TimeoutError()>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 853, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 323, in _agenerate\n",
      "    final_chunk = await self._achat_stream_with_aggregation(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 244, in _achat_stream_with_aggregation\n",
      "    async for stream_resp in self._acreate_chat_stream(messages, stop, **kwargs):\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 203, in _acreate_chat_stream\n",
      "    async for stream_resp in self._acreate_stream(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\langchain_community\\llms\\ollama.py\", line 317, in _acreate_stream\n",
      "    async for line in response.content:\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\aiohttp\\streams.py\", line 50, in __anext__\n",
      "    rv = await self.read_func()\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\aiohttp\\streams.py\", line 317, in readline\n",
      "    return await self.readuntil()\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\aiohttp\\streams.py\", line 351, in readuntil\n",
      "    await self._wait(\"readuntil\")\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\aiohttp\\streams.py\", line 312, in _wait\n",
      "    await waiter\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 285, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 234, in __step\n",
      "    result = coro.throw(exc)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 266, in _ascore\n",
      "    nli_result = await self.llm.generate(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\llms\\base.py\", line 93, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\tenacity\\_asyncio.py\", line 88, in async_wrapped\n",
      "    return await fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\tenacity\\_asyncio.py\", line 47, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\tenacity\\__init__.py\", line 314, in iter\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\concurrent\\futures\\_base.py\", line 451, in result\n",
      "    return self.__get_result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\concurrent\\futures\\_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\tenacity\\_asyncio.py\", line 50, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\llms\\base.py\", line 178, in agenerate_text\n",
      "    result = await self.langchain_llm.agenerate_prompt(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 708, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in agenerate\n",
      "    results = await asyncio.gather(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 456, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 458, in wait_for\n",
      "    raise exceptions.TimeoutError() from exc\n",
      "asyncio.exceptions.TimeoutError\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-6795' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('llm must be set to compute score')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 265, in _ascore\n",
      "    p_value = self._create_nli_prompt(row, statements)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 200, in _create_nli_prompt\n",
      "    assert self.llm is not None, \"llm must be set to compute score\"\n",
      "AssertionError: llm must be set to compute score\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-6797' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=TimeoutError()>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 234, in __step\n",
      "    result = coro.throw(exc)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 853, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 323, in _agenerate\n",
      "    final_chunk = await self._achat_stream_with_aggregation(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 252, in _achat_stream_with_aggregation\n",
      "    await run_manager.on_llm_new_token(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\langchain_core\\callbacks\\manager.py\", line 237, in wrapped\n",
      "    return await asyncio.shield(func(*args, **kwargs))\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 285, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 234, in __step\n",
      "    result = coro.throw(exc)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 266, in _ascore\n",
      "    nli_result = await self.llm.generate(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\llms\\base.py\", line 93, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\tenacity\\_asyncio.py\", line 88, in async_wrapped\n",
      "    return await fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\tenacity\\_asyncio.py\", line 47, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\tenacity\\__init__.py\", line 314, in iter\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\concurrent\\futures\\_base.py\", line 451, in result\n",
      "    return self.__get_result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\concurrent\\futures\\_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\tenacity\\_asyncio.py\", line 50, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\llms\\base.py\", line 178, in agenerate_text\n",
      "    result = await self.langchain_llm.agenerate_prompt(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 708, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in agenerate\n",
      "    results = await asyncio.gather(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 456, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 458, in wait_for\n",
      "    raise exceptions.TimeoutError() from exc\n",
      "asyncio.exceptions.TimeoutError\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-10615' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('llm must be set to compute score')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 265, in _ascore\n",
      "    p_value = self._create_nli_prompt(row, statements)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 200, in _create_nli_prompt\n",
      "    assert self.llm is not None, \"llm must be set to compute score\"\n",
      "AssertionError: llm must be set to compute score\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-10616' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('llm must be set to compute score')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 265, in _ascore\n",
      "    p_value = self._create_nli_prompt(row, statements)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 200, in _create_nli_prompt\n",
      "    assert self.llm is not None, \"llm must be set to compute score\"\n",
      "AssertionError: llm must be set to compute score\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-10617' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('llm must be set to compute score')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 265, in _ascore\n",
      "    p_value = self._create_nli_prompt(row, statements)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 200, in _create_nli_prompt\n",
      "    assert self.llm is not None, \"llm must be set to compute score\"\n",
      "AssertionError: llm must be set to compute score\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-10618' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=AssertionError('llm must be set to compute score')>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 265, in _ascore\n",
      "    p_value = self._create_nli_prompt(row, statements)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 200, in _create_nli_prompt\n",
      "    assert self.llm is not None, \"llm must be set to compute score\"\n",
      "AssertionError: llm must be set to compute score\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-10611' coro=<as_completed.<locals>.sema_coro() done, defined at c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py:35> exception=TimeoutError()>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 853, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 323, in _agenerate\n",
      "    final_chunk = await self._achat_stream_with_aggregation(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 244, in _achat_stream_with_aggregation\n",
      "    async for stream_resp in self._acreate_chat_stream(messages, stop, **kwargs):\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 203, in _acreate_chat_stream\n",
      "    async for stream_resp in self._acreate_stream(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\langchain_community\\llms\\ollama.py\", line 317, in _acreate_stream\n",
      "    async for line in response.content:\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\aiohttp\\streams.py\", line 50, in __anext__\n",
      "    rv = await self.read_func()\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\aiohttp\\streams.py\", line 317, in readline\n",
      "    return await self.readuntil()\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\aiohttp\\streams.py\", line 351, in readuntil\n",
      "    await self._wait(\"readuntil\")\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\aiohttp\\streams.py\", line 312, in _wait\n",
      "    await waiter\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 285, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 234, in __step\n",
      "    result = coro.throw(exc)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 266, in _ascore\n",
      "    nli_result = await self.llm.generate(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\llms\\base.py\", line 93, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\tenacity\\_asyncio.py\", line 88, in async_wrapped\n",
      "    return await fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\tenacity\\_asyncio.py\", line 47, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\tenacity\\__init__.py\", line 314, in iter\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\concurrent\\futures\\_base.py\", line 451, in result\n",
      "    return self.__get_result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\concurrent\\futures\\_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\tenacity\\_asyncio.py\", line 50, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\llms\\base.py\", line 178, in agenerate_text\n",
      "    result = await self.langchain_llm.agenerate_prompt(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 708, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 634, in agenerate\n",
      "    results = await asyncio.gather(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 456, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 37, in sema_coro\n",
      "    return await coro\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 109, in wrapped_callable_async\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\irvin\\Documents\\GitHub\\support-chatbot\\venv\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"C:\\Users\\irvin\\anaconda3\\lib\\asyncio\\tasks.py\", line 458, in wait_for\n",
      "    raise exceptions.TimeoutError() from exc\n",
      "asyncio.exceptions.TimeoutError\n"
     ]
    }
   ],
   "source": [
    "for question in data_samples['question']:\n",
    "    answer = conversational_rag_chain.invoke(\n",
    "        {\"input\": question},\n",
    "        config={\n",
    "            \"configurable\": {\"session_id\": \"abc123\"}\n",
    "        },\n",
    "    )[\"answer\"]\n",
    "    data_samples['answer'].append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': ['What is self-attention?',\n",
       "  'How many identical layers does the encoder of the transformer have?'],\n",
       " 'answer': [\"The text doesn't explicitly define what self-attention is, but based on the context, it appears to be a type of layer in a neural network that allows the model to attend to different parts of the input sequence in order to compute a representation of the sequence.\",\n",
       "  'The encoder of the transformer has N=6 identical layers.'],\n",
       " 'contexts': [['Self-attention, sometimes called intra-attention is an attention mechanism relating different positions of a single sequence in order to compute a representation of the sequence.'],\n",
       "  ['The encoder is composed of a stack of N = 6 identical layers.']]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70cad3941cc542d3b18962f9c3bbc3db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>contexts</th>\n",
       "      <th>faithfulness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is self-attention?</td>\n",
       "      <td>The text doesn't explicitly define what self-a...</td>\n",
       "      <td>[Self-attention, sometimes called intra-attent...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How many identical layers does the encoder of ...</td>\n",
       "      <td>The encoder of the transformer has N=6 identic...</td>\n",
       "      <td>[The encoder is composed of a stack of N = 6 i...</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0                            What is self-attention?   \n",
       "1  How many identical layers does the encoder of ...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  The text doesn't explicitly define what self-a...   \n",
       "1  The encoder of the transformer has N=6 identic...   \n",
       "\n",
       "                                            contexts  faithfulness  \n",
       "0  [Self-attention, sometimes called intra-attent...      1.000000  \n",
       "1  [The encoder is composed of a stack of N = 6 i...      0.333333  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import faithfulness \n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "dataset = Dataset.from_dict(data_samples)\n",
    "score = evaluate(dataset,metrics=[faithfulness], llm=ChatOllama(model='mistral'), embeddings=OllamaEmbeddings(model='mistral'))\n",
    "score.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37a985b16ad24e8484db041b873fce97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>contexts</th>\n",
       "      <th>answer_relevancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is self-attention?</td>\n",
       "      <td>The text doesn't explicitly define what self-a...</td>\n",
       "      <td>[Self-attention, sometimes called intra-attent...</td>\n",
       "      <td>0.719229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How many identical layers does the encoder of ...</td>\n",
       "      <td>The encoder of the transformer has N=6 identic...</td>\n",
       "      <td>[The encoder is composed of a stack of N = 6 i...</td>\n",
       "      <td>0.781346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0                            What is self-attention?   \n",
       "1  How many identical layers does the encoder of ...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  The text doesn't explicitly define what self-a...   \n",
       "1  The encoder of the transformer has N=6 identic...   \n",
       "\n",
       "                                            contexts  answer_relevancy  \n",
       "0  [Self-attention, sometimes called intra-attent...          0.719229  \n",
       "1  [The encoder is composed of a stack of N = 6 i...          0.781346  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset \n",
    "from ragas.metrics import answer_relevancy\n",
    "from ragas import evaluate\n",
    "\n",
    "# data_samples = {\n",
    "#     'question': ['When was the first super bowl?', 'Who won the most super bowls?'],\n",
    "#     'answer': ['The first superbowl was held on Jan 15, 1967', 'The most super bowls have been won by The New England Patriots'],\n",
    "#     'contexts' : [['The First AFLNFL World Championship Game was an American football game played on January 15, 1967, at the Los Angeles Memorial Coliseum in Los Angeles,'], \n",
    "#     ['The Green Bay Packers...Green Bay, Wisconsin.','The Packers compete...Football Conference']],\n",
    "# }\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "dataset = Dataset.from_dict(data_samples)\n",
    "score = evaluate(dataset,metrics=[answer_relevancy], llm=ChatOllama(model='mistral'), embeddings=OllamaEmbeddings(model='mistral'))\n",
    "score.to_pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_samples = {\n",
    "    'question': \n",
    "        [\n",
    "            'What is the fundamental mechanism that the Transformer model relies on?', \n",
    "            'How does the Transformer model handle global dependencies?',\n",
    "            'What components of traditional models does the Transformer model replace?',\n",
    "            'How many layers does the Transformer model typically have?',\n",
    "            'What are the two main sub-layers in each Transformer layer?',\n",
    "            'What is the role of the multi-head self-attention mechanism in the Transformer model?',\n",
    "            'What does each sub-layer in the Transformer model use for normalization?',\n",
    "            'What is added to the input embeddings and output embeddings in the Transformer model?',\n",
    "            'Why are positional encodings used in the Transformer model?',\n",
    "            'How are positional encodings generated in the Transformer model?',\n",
    "            'What is the dimension of the input and output embeddings in the Transformer model?',\n",
    "            # 'What optimization technique is used during the training of the Transformer model?',\n",
    "            # 'What regularization technique is employed in the Transformer model?',\n",
    "            # 'How is scaled dot-product attention computed in the Transformer model?',\n",
    "            # 'What is multi-head attention in the Transformer model?',\n",
    "            # 'What advantage does multi-head attention provide?',\n",
    "            # 'What are the dimensions of the queries, keys, and values in each head of the multi-head attention mechanism?',\n",
    "            # 'What activation function is used in the feed-forward network of the Transformer model?',\n",
    "            # 'What is the main advantage of using attention mechanisms over recurrent layers?',\n",
    "            # 'What metric is used to evaluate the performance of the Transformer model?',\n",
    "            # 'How does the Transformer model perform compared to previous state-of-the-art models?',\n",
    "            # 'How is the final output of the Transformer model produced?'\n",
    "        ],\n",
    "    'answer': \n",
    "        [],\n",
    "    'contexts' :\n",
    "        [\n",
    "            ['Instead of using recurrence, the Transformer uses an attention mechanism to draw global dependencies between input and output.'], \n",
    "            ['The Transformer uses an attention mechanism to draw global dependencies between input and output.'],\n",
    "            ['Our model, the Transformer, is based solely on attention mechanisms, dispensing with recurrence and convolutions entirely.'],\n",
    "            ['The Transformer model architecture consists of a stack of six identical layers.'],\n",
    "            ['Each layer has two sub-layers. The first is a multi-head self-attention mechanism, and the second is a simple, position-wise fully connected feed-forward network.'],\n",
    "            ['The first sub-layer in each layer is a multi-head self-attention mechanism, which allows the model to focus on different parts of the input sequence.'],\n",
    "            ['We employ a residual connection around each of the two sub-layers, followed by layer normalization.'],\n",
    "            ['We add positional encodings to the input embeddings and the output embeddings at the bottoms of the encoder and decoder stacks.'],\n",
    "            ['Since our model contains no recurrence and no convolution, in order for the model to make use of the order of the sequence, we must inject some information about the relative or absolute position of the tokens in the sequence.'],\n",
    "            ['We use sine and cosine functions of different frequencies as positional encodings.'],\n",
    "            ['We use learned embeddings to convert the input tokens and output tokens to vectors of dimension d_model.'],\n",
    "            # ['We use the Adam optimizer with 1 = 0.9, 2 = 0.98, and  = 10^-9.'],\n",
    "            # ['We employ residual dropout, with a rate of P_drop = 0.1.'],\n",
    "            # ['The input consists of queries and keys of dimension dk, and values of dimension dv. We compute the dot products of the query with all keys, divide each by dk, and apply a softmax function to obtain the weights on the values.'],\n",
    "            # ['Multi-head attention consists of several attention layers running in parallel, called heads. Each head has its own set of weights for linear transformations of the queries, keys, and values.'],\n",
    "            # ['Using multi-head attention allows the model to jointly attend to information from different representation subspaces at different positions.'],\n",
    "            # ['Each head has a dimension of dk = d_model/h.'],\n",
    "            # ['We apply the ReLU activation function after the first linear transformation in the feed-forward network.'],\n",
    "            # ['Attention mechanisms can draw dependencies regardless of their distance in the input or output sequences, which makes them more parallelizable than recurrent layers.'],\n",
    "            # ['We report results using the BLEU score, a common metric for evaluating the quality of machine-translated text.'],\n",
    "            # ['Our Transformer model outperforms the previously best reported models on both the WMT 2014 English-to-German and English-to-French translation tasks.'],\n",
    "            # [\"The decoder generates the output sequence one token at a time, with each generated token being conditioned on the previously generated tokens and the encoder's output.\"]\n",
    "        ],\n",
    "    'ground_truth' :\n",
    "        [\n",
    "            'The fundamental mechanism is the attention mechanism.',\n",
    "            'By using an attention mechanism.',\n",
    "            'It replaces recurrence and convolutions.',\n",
    "            'It typically has six layers.',\n",
    "            'A multi-head self-attention mechanism and a fully connected feed-forward network.',\n",
    "            'It allows the model to focus on different parts of the input sequence.',\n",
    "            'Layer normalization.',\n",
    "            'Positional encodings.',\n",
    "            'To inject information about the relative or absolute position of the tokens in the sequence.',\n",
    "            'Using sine and cosine functions of different frequencies.',\n",
    "            'The dimension is d_model.',\n",
    "            # 'The Adam optimizer.',\n",
    "            # 'Residual dropout.',\n",
    "            # 'By computing the dot products of the query with all keys, dividing each by dk, and applying a softmax function.',\n",
    "            # 'It consists of several attention layers running in parallel, each with its own set of weights.',\n",
    "            # 'It allows the model to jointly attend to information from different representation subspaces at different positions.',\n",
    "            # 'The dimension is dk = d_model/h.',\n",
    "            # 'The ReLU activation function.',\n",
    "            # 'They can draw dependencies regardless of their distance and are more parallelizable.',\n",
    "            # 'The BLEU score.',\n",
    "            # 'It outperforms the previously best reported models.',\n",
    "            # \"The decoder generates the output sequence one token at a time, conditioned on previously generated tokens and the encoder's output.\"\n",
    "        ]\n",
    "}\n",
    "\n",
    "for question in data_samples['question']:\n",
    "    answer = conversational_rag_chain.invoke(\n",
    "        {\"input\": question},\n",
    "        config={\n",
    "            \"configurable\": {\"session_id\": \"abc123\"}\n",
    "        },\n",
    "    )[\"answer\"]\n",
    "    data_samples['answer'].append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e9d6fe6e49f4611891f003343b91176",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>faithfulness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the fundamental mechanism that the Tra...</td>\n",
       "      <td>The fundamental mechanism that the Transformer...</td>\n",
       "      <td>[Instead of using recurrence, the Transformer ...</td>\n",
       "      <td>The fundamental mechanism is the attention mec...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How does the Transformer model handle global d...</td>\n",
       "      <td>The Transformer model handles global dependenc...</td>\n",
       "      <td>[The Transformer uses an attention mechanism t...</td>\n",
       "      <td>By using an attention mechanism.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What components of traditional models does the...</td>\n",
       "      <td>The Transformer model replaces recurrence and ...</td>\n",
       "      <td>[Our model, the Transformer, is based solely o...</td>\n",
       "      <td>It replaces recurrence and convolutions.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How many layers does the Transformer model typ...</td>\n",
       "      <td>The Transformer model typically has 6 identica...</td>\n",
       "      <td>[The Transformer model architecture consists o...</td>\n",
       "      <td>It typically has six layers.</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are the two main sub-layers in each Trans...</td>\n",
       "      <td>The two main sub-layers in each Transformer la...</td>\n",
       "      <td>[Each layer has two sub-layers. The first is a...</td>\n",
       "      <td>A multi-head self-attention mechanism and a fu...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What is the role of the multi-head self-attent...</td>\n",
       "      <td>The role of the multi-head self-attention mech...</td>\n",
       "      <td>[The first sub-layer in each layer is a multi-...</td>\n",
       "      <td>It allows the model to focus on different part...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What does each sub-layer in the Transformer mo...</td>\n",
       "      <td>Each sub-layer in the Transformer model uses L...</td>\n",
       "      <td>[We employ a residual connection around each o...</td>\n",
       "      <td>Layer normalization.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What is added to the input embeddings and outp...</td>\n",
       "      <td>Positional encodings are added to the input em...</td>\n",
       "      <td>[We add positional encodings to the input embe...</td>\n",
       "      <td>Positional encodings.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Why are positional encodings used in the Trans...</td>\n",
       "      <td>Positional encodings are used in the Transform...</td>\n",
       "      <td>[Since our model contains no recurrence and no...</td>\n",
       "      <td>To inject information about the relative or ab...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>How are positional encodings generated in the ...</td>\n",
       "      <td>Positional encodings are generated using sinus...</td>\n",
       "      <td>[We use sine and cosine functions of different...</td>\n",
       "      <td>Using sine and cosine functions of different f...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>What is the dimension of the input and output ...</td>\n",
       "      <td>The dimension of the input and output embeddin...</td>\n",
       "      <td>[We use learned embeddings to convert the inpu...</td>\n",
       "      <td>The dimension is d_model.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question  \\\n",
       "0   What is the fundamental mechanism that the Tra...   \n",
       "1   How does the Transformer model handle global d...   \n",
       "2   What components of traditional models does the...   \n",
       "3   How many layers does the Transformer model typ...   \n",
       "4   What are the two main sub-layers in each Trans...   \n",
       "5   What is the role of the multi-head self-attent...   \n",
       "6   What does each sub-layer in the Transformer mo...   \n",
       "7   What is added to the input embeddings and outp...   \n",
       "8   Why are positional encodings used in the Trans...   \n",
       "9   How are positional encodings generated in the ...   \n",
       "10  What is the dimension of the input and output ...   \n",
       "\n",
       "                                               answer  \\\n",
       "0   The fundamental mechanism that the Transformer...   \n",
       "1   The Transformer model handles global dependenc...   \n",
       "2   The Transformer model replaces recurrence and ...   \n",
       "3   The Transformer model typically has 6 identica...   \n",
       "4   The two main sub-layers in each Transformer la...   \n",
       "5   The role of the multi-head self-attention mech...   \n",
       "6   Each sub-layer in the Transformer model uses L...   \n",
       "7   Positional encodings are added to the input em...   \n",
       "8   Positional encodings are used in the Transform...   \n",
       "9   Positional encodings are generated using sinus...   \n",
       "10  The dimension of the input and output embeddin...   \n",
       "\n",
       "                                             contexts  \\\n",
       "0   [Instead of using recurrence, the Transformer ...   \n",
       "1   [The Transformer uses an attention mechanism t...   \n",
       "2   [Our model, the Transformer, is based solely o...   \n",
       "3   [The Transformer model architecture consists o...   \n",
       "4   [Each layer has two sub-layers. The first is a...   \n",
       "5   [The first sub-layer in each layer is a multi-...   \n",
       "6   [We employ a residual connection around each o...   \n",
       "7   [We add positional encodings to the input embe...   \n",
       "8   [Since our model contains no recurrence and no...   \n",
       "9   [We use sine and cosine functions of different...   \n",
       "10  [We use learned embeddings to convert the inpu...   \n",
       "\n",
       "                                         ground_truth  faithfulness  \n",
       "0   The fundamental mechanism is the attention mec...           1.0  \n",
       "1                    By using an attention mechanism.           1.0  \n",
       "2            It replaces recurrence and convolutions.           1.0  \n",
       "3                        It typically has six layers.           0.5  \n",
       "4   A multi-head self-attention mechanism and a fu...           1.0  \n",
       "5   It allows the model to focus on different part...           1.0  \n",
       "6                                Layer normalization.           0.0  \n",
       "7                               Positional encodings.           1.0  \n",
       "8   To inject information about the relative or ab...           1.0  \n",
       "9   Using sine and cosine functions of different f...           1.0  \n",
       "10                          The dimension is d_model.           1.0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas.metrics import (\n",
    "    answer_relevancy,\n",
    "    faithfulness,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    "    answer_similarity,\n",
    "    answer_correctness,\n",
    ")\n",
    "from ragas.metrics.critique import harmfulness\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "dataset = Dataset.from_dict(data_samples)\n",
    "score = evaluate(dataset,metrics=[faithfulness], llm=ChatOllama(model='mistral'), embeddings=OllamaEmbeddings(model='mistral'))\n",
    "score.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'faithfulness': 0.8636}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>faithfulness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the fundamental mechanism that the Tra...</td>\n",
       "      <td>The fundamental mechanism that the Transformer...</td>\n",
       "      <td>[Instead of using recurrence, the Transformer ...</td>\n",
       "      <td>The fundamental mechanism is the attention mec...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How does the Transformer model handle global d...</td>\n",
       "      <td>The Transformer model handles global dependenc...</td>\n",
       "      <td>[The Transformer uses an attention mechanism t...</td>\n",
       "      <td>By using an attention mechanism.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What components of traditional models does the...</td>\n",
       "      <td>The Transformer model replaces recurrence and ...</td>\n",
       "      <td>[Our model, the Transformer, is based solely o...</td>\n",
       "      <td>It replaces recurrence and convolutions.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How many layers does the Transformer model typ...</td>\n",
       "      <td>The Transformer model typically has 6 identica...</td>\n",
       "      <td>[The Transformer model architecture consists o...</td>\n",
       "      <td>It typically has six layers.</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are the two main sub-layers in each Trans...</td>\n",
       "      <td>The two main sub-layers in each Transformer la...</td>\n",
       "      <td>[Each layer has two sub-layers. The first is a...</td>\n",
       "      <td>A multi-head self-attention mechanism and a fu...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What is the role of the multi-head self-attent...</td>\n",
       "      <td>The role of the multi-head self-attention mech...</td>\n",
       "      <td>[The first sub-layer in each layer is a multi-...</td>\n",
       "      <td>It allows the model to focus on different part...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What does each sub-layer in the Transformer mo...</td>\n",
       "      <td>Each sub-layer in the Transformer model uses L...</td>\n",
       "      <td>[We employ a residual connection around each o...</td>\n",
       "      <td>Layer normalization.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What is added to the input embeddings and outp...</td>\n",
       "      <td>Positional encodings are added to the input em...</td>\n",
       "      <td>[We add positional encodings to the input embe...</td>\n",
       "      <td>Positional encodings.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Why are positional encodings used in the Trans...</td>\n",
       "      <td>Positional encodings are used in the Transform...</td>\n",
       "      <td>[Since our model contains no recurrence and no...</td>\n",
       "      <td>To inject information about the relative or ab...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>How are positional encodings generated in the ...</td>\n",
       "      <td>Positional encodings are generated using sinus...</td>\n",
       "      <td>[We use sine and cosine functions of different...</td>\n",
       "      <td>Using sine and cosine functions of different f...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>What is the dimension of the input and output ...</td>\n",
       "      <td>The dimension of the input and output embeddin...</td>\n",
       "      <td>[We use learned embeddings to convert the inpu...</td>\n",
       "      <td>The dimension is d_model.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question  \\\n",
       "0   What is the fundamental mechanism that the Tra...   \n",
       "1   How does the Transformer model handle global d...   \n",
       "2   What components of traditional models does the...   \n",
       "3   How many layers does the Transformer model typ...   \n",
       "4   What are the two main sub-layers in each Trans...   \n",
       "5   What is the role of the multi-head self-attent...   \n",
       "6   What does each sub-layer in the Transformer mo...   \n",
       "7   What is added to the input embeddings and outp...   \n",
       "8   Why are positional encodings used in the Trans...   \n",
       "9   How are positional encodings generated in the ...   \n",
       "10  What is the dimension of the input and output ...   \n",
       "\n",
       "                                               answer  \\\n",
       "0   The fundamental mechanism that the Transformer...   \n",
       "1   The Transformer model handles global dependenc...   \n",
       "2   The Transformer model replaces recurrence and ...   \n",
       "3   The Transformer model typically has 6 identica...   \n",
       "4   The two main sub-layers in each Transformer la...   \n",
       "5   The role of the multi-head self-attention mech...   \n",
       "6   Each sub-layer in the Transformer model uses L...   \n",
       "7   Positional encodings are added to the input em...   \n",
       "8   Positional encodings are used in the Transform...   \n",
       "9   Positional encodings are generated using sinus...   \n",
       "10  The dimension of the input and output embeddin...   \n",
       "\n",
       "                                             contexts  \\\n",
       "0   [Instead of using recurrence, the Transformer ...   \n",
       "1   [The Transformer uses an attention mechanism t...   \n",
       "2   [Our model, the Transformer, is based solely o...   \n",
       "3   [The Transformer model architecture consists o...   \n",
       "4   [Each layer has two sub-layers. The first is a...   \n",
       "5   [The first sub-layer in each layer is a multi-...   \n",
       "6   [We employ a residual connection around each o...   \n",
       "7   [We add positional encodings to the input embe...   \n",
       "8   [Since our model contains no recurrence and no...   \n",
       "9   [We use sine and cosine functions of different...   \n",
       "10  [We use learned embeddings to convert the inpu...   \n",
       "\n",
       "                                         ground_truth  faithfulness  \n",
       "0   The fundamental mechanism is the attention mec...           1.0  \n",
       "1                    By using an attention mechanism.           1.0  \n",
       "2            It replaces recurrence and convolutions.           1.0  \n",
       "3                        It typically has six layers.           0.5  \n",
       "4   A multi-head self-attention mechanism and a fu...           1.0  \n",
       "5   It allows the model to focus on different part...           1.0  \n",
       "6                                Layer normalization.           0.0  \n",
       "7                               Positional encodings.           1.0  \n",
       "8   To inject information about the relative or ab...           1.0  \n",
       "9   Using sine and cosine functions of different f...           1.0  \n",
       "10                          The dimension is d_model.           1.0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8636363636363636"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score['faithfulness']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
